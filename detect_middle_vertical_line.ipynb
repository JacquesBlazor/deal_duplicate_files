{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "# Set the image path\n",
    "path = \"./\"\n",
    "fileName = \"usb-0002.jpg\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "-1"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the image in default mode:\n",
    "inputImage = cv2.imread(os.path.join(path, fileName))\n",
    "# Show current crop:\n",
    "cv2.imshow(\"InputImage\", inputImage)\n",
    "cv2.waitKey(0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "-1"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert RGB to grayscale:\n",
    "grayscaleImage = cv2.cvtColor(inputImage, cv2.COLOR_BGR2GRAY)\n",
    "cv2.imshow(\"GrayscaleImage\", grayscaleImage)\n",
    "cv2.waitKey(0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "(2480, 3507)"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the sample ROI and crop it:\n",
    "(imageHeight, imageWidth) = grayscaleImage.shape[:2]\n",
    "imageHeight, imageWidth"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "(0, 74, 3507, 74)"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the sample ROI:\n",
    "roiX = 0\n",
    "roiY = int(0.03 * imageHeight)\n",
    "roiWidth = imageWidth\n",
    "roiHeight = int(0.03 * imageHeight)\n",
    "roiX, roiY, roiWidth, roiHeight"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "-1"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Crop the the sample ROI image:\n",
    "imageRoi = grayscaleImage[roiY:roiY+roiHeight, roiX:roiWidth]\n",
    "cv2.imshow(\"ImageRoi\", imageRoi)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "-1"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Thresholding:\n",
    "_, binaryImage = cv2.threshold(imageRoi, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "cv2.imshow(\"ImageRoi\", binaryImage)\n",
    "cv2.waitKey(0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "data": {
      "text/plain": "-1"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reduce the ROI to a 1 x imageWidth row:\n",
    "reducedImg = cv2.reduce(binaryImage, 0, cv2.REDUCE_MAX)\n",
    "cv2.imshow(\"ReducedImg\", reducedImg)\n",
    "cv2.waitKey(0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "data": {
      "text/plain": "(1, 3507)"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reducedImg.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got Jump at:1729\n"
     ]
    }
   ],
   "source": [
    "# Store the transition positions here:\n",
    "linePositions = []\n",
    "\n",
    "# Find transitions from 0 to 255:\n",
    "pastPixel = 255\n",
    "for x in range(reducedImg.shape[1]):\n",
    "    # Get current pixel:\n",
    "    currentPixel = reducedImg[0, x]\n",
    "    # Check for the \"jumps\":\n",
    "    if currentPixel == 255 and pastPixel == 0:\n",
    "        # Store the jump locations in list:\n",
    "        print(\"Got Jump at:\"+str(x))\n",
    "        linePositions.append(x)\n",
    "    # Set current pixel to past pixel:\n",
    "    pastPixel = currentPixel"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "data": {
      "text/plain": "[1729]"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linePositions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "data": {
      "text/plain": "3507"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reducedImg.shape[1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "data": {
      "text/plain": "2480"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imageHeight"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "linePositions.insert(0, 0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "data": {
      "text/plain": "[0, 1729]"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linePositions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "data": {
      "text/plain": "(3507, 1753)"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxWidth = reducedImg.shape[1]\n",
    "closestMiddle = maxWidth // 2\n",
    "maxWidth, closestMiddle"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "# Crop pages:\n",
    "if len(linePositions) == 1:\n",
    "    linePositions.insert(0, 0)\n",
    "elif len(linePositions) > 2:\n",
    "    maxWidth = reducedImg.shape[1]\n",
    "    halfWidth = maxWidth // 2\n",
    "    closestMiddle = maxWidth\n",
    "    for i in range(len(linePositions)):\n",
    "        if abs(halfWidth - i) < closestMiddle and (abs(halfWidth - i) > (halfWidth // 2)) and ((abs(halfWidth - i) < ((halfWidth // 2) * 3))):\n",
    "            closestMiddle = i\n",
    "    if abs(closestMiddle - halfWidth) > 50:\n",
    "        closestMiddle = halfWidth\n",
    "    linePositions = [0, closestMiddle]\n",
    "for i in range(len(linePositions)):\n",
    "    # Get top left:\n",
    "    cropX = linePositions[i]\n",
    "\n",
    "    # Get top left:\n",
    "    if i != len(linePositions)-1:\n",
    "        # Get point from the list:\n",
    "        cropWidth = linePositions[i+1]\n",
    "    else:\n",
    "        # Set point from the image's original width:\n",
    "        cropWidth = reducedImg.shape[1]\n",
    "\n",
    "    # Crop page:\n",
    "    cropY = 0\n",
    "    cropHeight = imageHeight\n",
    "    currentCrop = inputImage[cropY:cropHeight, cropX:cropWidth]\n",
    "\n",
    "    # Show current crop:\n",
    "    #cv2.imshow(\"CurrentCrop\", currentCrop)\n",
    "    cv2.imwrite(f'CurrentCrop_{i}.jpg', currentCrop)\n",
    "    #cv2.waitKey(0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}