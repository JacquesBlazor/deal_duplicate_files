{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "target = 'E:/.developing_env/duplicated_files/groupby_method/'\n",
    "df = pd.read_csv('df_index.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval_group_id: 1057\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'D:\\\\Advanced Analytics with Spark Patterns for Learning from Data at Scale'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_26528/2471105560.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     10\u001B[0m \u001B[0mreshape_frame\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mDataFrame\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     11\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mfolder\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mfolder_lists\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 12\u001B[1;33m     \u001B[1;32mfor\u001B[0m \u001B[0mgroup_name\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mgroup_frame\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mloc_folders\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mfolder\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     13\u001B[0m         \u001B[0mreshape_frame\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mconcat\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mreshape_frame\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mgroup_frame\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     14\u001B[0m \u001B[0mgroups_dump\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mreshape_frame\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'組別'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0munique\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyError\u001B[0m: 'D:\\\\Advanced Analytics with Spark Patterns for Learning from Data at Scale'"
     ]
    }
   ],
   "source": [
    "eval_group_id = df['組別'].iloc[0]\n",
    "print('eval_group_id:', eval_group_id)\n",
    "folder_lists = list(df[df['組別'] == eval_group_id]['磁碟機根目錄'].unique())\n",
    "df_index_drive_root = df.set_index('磁碟機根目錄')\n",
    "loc_folders = {}\n",
    "folder_names = []\n",
    "for folder in folder_lists:\n",
    "    if isinstance(df_index_drive_root.loc[folder], pd.core.frame.DataFrame):\n",
    "        loc_folders[folder] = df_index_drive_root.loc[folder].groupby('檔案資料夾')\n",
    "reshape_frame = pd.DataFrame()\n",
    "for folder in folder_lists:\n",
    "    for group_name, group_frame in loc_folders[folder]:\n",
    "        reshape_frame = pd.concat([reshape_frame, group_frame])\n",
    "groups_dump = reshape_frame['組別'].unique()\n",
    "folder_name = ''.join(re.findall('[\\u4e00-\\u9fff]+|^[<>:/\\|?*\"]+', df[df['組別'] == eval_group_id]['磁碟機根目錄'].min()))\n",
    "file_path_name = os.path.join(target, f'{folder_name}{groups_dump[0]}{groups_dump[-1]}.csv')\n",
    "try:\n",
    "    reshape_frame = df[df['組別'].isin(groups_dump) == True].sort_values(['組別', '路徑'])\n",
    "    reshape_frame.set_index('磁碟機根目錄', inplace=True)\n",
    "    reshape_frame.to_csv(file_path_name, encoding='utf-8-sig')\n",
    "except Exception as e:\n",
    "    print(f'嘗試儲存 {file_path_name} 時發生錯誤: {e}')\n",
    "else:\n",
    "    del df_index_drive_root\n",
    "    del reshape_frame\n",
    "    del loc_folders\n",
    "    del folder_names\n",
    "    df.drop(df[df['組別'].isin(groups_dump) == True].index, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "{'Z:\\\\資訊書籍文件': <pandas.core.groupby.generic.DataFrameGroupBy object at 0x0000020E16EFC288>}"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loc_folders"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "eval_group_id = df['組別'].iloc[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "1057"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_group_id"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                 磁碟機根目錄    組別  檔案類型 磁碟機  \\\n3426  D:\\Advanced Analytics with Spark Patterns for ...  1057  .pdf  D:   \n3427                                          Z:\\資訊書籍文件  1057  .pdf  Z:   \n\n                                                    根目錄  \\\n3426  Advanced Analytics with Spark Patterns for Lea...   \n3427                                             資訊書籍文件   \n\n                                                    子目錄  \\\n3426                                                NaN   \n3427  Advanced Analytics with Spark Patterns for Lea...   \n\n                                                  檔案資料夾  \\\n3426  Advanced Analytics with Spark Patterns for Lea...   \n3427  Advanced Analytics with Spark Patterns for Lea...   \n\n                                                   檔案名稱  \\\n3426  Advanced Analytics with Spark - Patterns for L...   \n3427  Advanced Analytics with Spark - Patterns for L...   \n\n                                                     路徑       大小  \\\n3426  D:\\Advanced Analytics with Spark Patterns for ...  5007564   \n3427  Z:\\資訊書籍文件\\Advanced Analytics with Spark Patter...  5007564   \n\n                       新增日期                   修改日期  \n3426  2021/8/18 上午 02:35:10  2020/2/25 上午 02:22:09  \n3427  2020/2/25 上午 02:19:59  2020/2/25 上午 02:22:09  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>磁碟機根目錄</th>\n      <th>組別</th>\n      <th>檔案類型</th>\n      <th>磁碟機</th>\n      <th>根目錄</th>\n      <th>子目錄</th>\n      <th>檔案資料夾</th>\n      <th>檔案名稱</th>\n      <th>路徑</th>\n      <th>大小</th>\n      <th>新增日期</th>\n      <th>修改日期</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3426</th>\n      <td>D:\\Advanced Analytics with Spark Patterns for ...</td>\n      <td>1057</td>\n      <td>.pdf</td>\n      <td>D:</td>\n      <td>Advanced Analytics with Spark Patterns for Lea...</td>\n      <td>NaN</td>\n      <td>Advanced Analytics with Spark Patterns for Lea...</td>\n      <td>Advanced Analytics with Spark - Patterns for L...</td>\n      <td>D:\\Advanced Analytics with Spark Patterns for ...</td>\n      <td>5007564</td>\n      <td>2021/8/18 上午 02:35:10</td>\n      <td>2020/2/25 上午 02:22:09</td>\n    </tr>\n    <tr>\n      <th>3427</th>\n      <td>Z:\\資訊書籍文件</td>\n      <td>1057</td>\n      <td>.pdf</td>\n      <td>Z:</td>\n      <td>資訊書籍文件</td>\n      <td>Advanced Analytics with Spark Patterns for Lea...</td>\n      <td>Advanced Analytics with Spark Patterns for Lea...</td>\n      <td>Advanced Analytics with Spark - Patterns for L...</td>\n      <td>Z:\\資訊書籍文件\\Advanced Analytics with Spark Patter...</td>\n      <td>5007564</td>\n      <td>2020/2/25 上午 02:19:59</td>\n      <td>2020/2/25 上午 02:22:09</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['組別']==eval_group_id]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}